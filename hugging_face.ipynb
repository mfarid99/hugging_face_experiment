{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d24a242-ad33-47bd-9306-c59e4278c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cpu\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: transformers in /Users/moe/miniconda3/lib/python3.13/site-packages (4.53.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/moe/miniconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/moe/miniconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/moe/miniconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/moe/miniconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: psutil in /Users/moe/miniconda3/lib/python3.13/site-packages (from accelerate) (5.9.0)\n",
      "INFO: pip is looking at multiple versions of accelerate to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.8.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is still looking at multiple versions of accelerate to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading accelerate-1.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.34.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.34.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.32.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.29.2-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.29.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.29.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.27.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.27.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.26.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.24.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.24.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading accelerate-0.20.2-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading accelerate-0.20.1-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading accelerate-0.20.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading accelerate-0.19.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading accelerate-0.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading accelerate-0.17.1-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading accelerate-0.17.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading accelerate-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading accelerate-0.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading accelerate-0.14.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading accelerate-0.13.2-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading accelerate-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading accelerate-0.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading accelerate-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading accelerate-0.11.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading accelerate-0.10.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading accelerate-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading accelerate-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading accelerate-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading accelerate-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading accelerate-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading accelerate-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading accelerate-0.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading accelerate-0.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading accelerate-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading accelerate-0.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading accelerate-0.3.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "  Downloading accelerate-0.2.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading accelerate-0.2.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading accelerate-0.1.0-py3-none-any.whl.metadata (9.7 kB)\n",
      "  Downloading accelerate-0.0.1-py3-none-any.whl.metadata (853 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/moe/miniconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/moe/miniconda3/lib/python3.13/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/moe/miniconda3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/moe/miniconda3/lib/python3.13/site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading accelerate-0.0.1-py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "!pip install transformers accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ed7bd-83cf-45de-927f-edcfd5900d96",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b7b87f-423b-4f4b-b3ee-2e0ea73f296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d67b07b-28da-44c8-9c4c-6fbe319657cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12b98baf-7ada-493a-8e81-bd766171ce33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9962688684463501}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(\"I cannot stand the color pink. It gets me very upset\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6e70241-3b44-4207-af25-aa62a5d9058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9840420484542847}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(\"I love roses but hate flowers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98baa3b1-6165-4f63-a9f2-f30c9fc424c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NER (will specify model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df8c2cd7-a19d-4822-b162-cb1607d8d6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model = \"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edf46833-f40c-4b4a-be0f-c9e1079b7bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.99964964,\n",
       "  'index': 1,\n",
       "  'word': 'Dave',\n",
       "  'start': 0,\n",
       "  'end': 4},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9991929,\n",
       "  'index': 2,\n",
       "  'word': 'Smith',\n",
       "  'start': 5,\n",
       "  'end': 10},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.99962246,\n",
       "  'index': 10,\n",
       "  'word': 'Charlie',\n",
       "  'start': 53,\n",
       "  'end': 60},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99951124,\n",
       "  'index': 11,\n",
       "  'word': 'Chaplin',\n",
       "  'start': 61,\n",
       "  'end': 68}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"Dave Smith debates are great especially the one with Charlie Chaplin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a92a9c-c255-4e2f-8b04-9eb7a4ac9ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model = \"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "769388eb-f699-42fe-86e5-451762ea1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'dance', 'eat', 'explore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92d7ca57-350b-400e-b05c-61da19765aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'explore', 'eat', 'dance'],\n",
       " 'scores': [0.6575334668159485,\n",
       "  0.3326416015625,\n",
       "  0.005616443231701851,\n",
       "  0.004208477679640055]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323492c-f55b-49a4-9dcb-8cc9b1220429",
   "metadata": {},
   "source": [
    "## Pre-Trained Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9904a952-f3c7-46b8-a0a4-2ffcd88f113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e105c773-e601-4ecc-88b3-c497e3291698",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6bc6714-adda-4d8c-a908-362064b25d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaee3631-6ebf-45cf-b35c-18af7619f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I am so excited to swim in the red sea\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb325744-ff75-4fe4-b312-1df8d12f245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 2572, 2061, 7568, 2000, 9880, 1999, 1996, 2417, 2712, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(sentence)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11c8819d-d278-4e89-8cb4-f5e5320820dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'so', 'excited', 'to', 'swim', 'in', 'the', 'red', 'sea']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer breaks sentence into tokens\n",
    "# the steps below is a step by step of what AutoTokenizer.from_pretrained() does\n",
    "\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fee541e-cdb0-4160-8219-90a75ef24559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045, 2572, 2061, 7568, 2000, 9880, 1999, 1996, 2417, 2712]\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db2fdb67-9295-4043-b4b6-83be1ad5a975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am so excited to swim in the red sea\n"
     ]
    }
   ],
   "source": [
    "decoded_ids = tokenizer.decode(token_ids)\n",
    "print(decoded_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e240e18-63ae-426a-9449-4b4a44ca2067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43f9750c-e1d5-4898-88b5-ec241c0ce52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(102)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d66ac-1981-4025-85b9-524a68f661f7",
   "metadata": {},
   "source": [
    "## Huggingface and Pytorch/Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "520b07c4-1aab-41f1-9ba8-cd8e4c4d9fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: POSITIVE\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Encode input\n",
    "sentence = \"I love working with Python!\"\n",
    "input_ids_pt = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    logits = model(**input_ids_pt).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "label = model.config.id2label[predicted_class_id]\n",
    "print(f\"Predicted label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b889e-73fb-41e6-8b4c-67c9f0f6d41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp310)",
   "language": "python",
   "name": "nlp310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
